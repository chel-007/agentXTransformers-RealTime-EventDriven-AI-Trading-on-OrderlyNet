{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f514e7b-12e0-4226-8269-d72c210e3ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install emp-orderly-types emp-orderly\n",
    "# !pip install ta\n",
    "# !pip install pandas-ta\n",
    "# !pip install google-auth\n",
    "# !pip install google-cloud-storage\n",
    "# !pip install pandas\n",
    "# !pip install aiohttp\n",
    "# !pip install requests\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install ipython\n",
    "# !pip install google-auth \n",
    "# !pip install google-cloud-storage\n",
    "\n",
    "# !pip install python-decimal\n",
    "# !pip install pynacl\n",
    "\n",
    "# !pip install base58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dbd6f83-c501-44c5-9877-de3bd5d420fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emp-orderly-types\n",
      "  Using cached emp_orderly_types-1.0-py3-none-any.whl.metadata (588 bytes)\n",
      "Collecting emp-orderly\n",
      "  Using cached emp_orderly-1.0-py3-none-any.whl.metadata (650 bytes)\n",
      "Collecting base58==2.1.1 (from emp-orderly-types)\n",
      "  Using cached base58-2.1.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: cryptography==42.0.5 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from emp-orderly-types) (42.0.5)\n",
      "Collecting eth-typing==4.1.0 (from emp-orderly-types)\n",
      "  Using cached eth_typing-4.1.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting eth-utils==4.1.0 (from emp-orderly-types)\n",
      "  Using cached eth_utils-4.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting httpx==0.27.0 (from emp-orderly-types)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pandas==2.2.2 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from emp-orderly-types) (2.2.2)\n",
      "Collecting pydantic>=2.7.0 (from emp-orderly-types)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting python-dotenv==1.0.1 (from emp-orderly-types)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting requests==2.31.0 (from emp-orderly-types)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from cryptography==42.0.5->emp-orderly-types) (1.16.0)\n",
      "Collecting eth-hash>=0.3.1 (from eth-utils==4.1.0->emp-orderly-types)\n",
      "  Using cached eth_hash-0.7.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: cytoolz>=0.10.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from eth-utils==4.1.0->emp-orderly-types) (0.12.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from httpx==0.27.0->emp-orderly-types) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from httpx==0.27.0->emp-orderly-types) (2024.6.2)\n",
      "Collecting httpcore==1.* (from httpx==0.27.0->emp-orderly-types)\n",
      "  Using cached httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from httpx==0.27.0->emp-orderly-types) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from httpx==0.27.0->emp-orderly-types) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas==2.2.2->emp-orderly-types) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas==2.2.2->emp-orderly-types) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas==2.2.2->emp-orderly-types) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas==2.2.2->emp-orderly-types) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from requests==2.31.0->emp-orderly-types) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from requests==2.31.0->emp-orderly-types) (2.2.2)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx==0.27.0->emp-orderly-types)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: bokeh==3.4.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from emp-orderly) (3.4.1)\n",
      "Collecting eth-rpc-py==0.1.8post6 (from emp-orderly)\n",
      "  Using cached eth_rpc_py-0.1.8.post6-py3-none-any.whl.metadata (787 bytes)\n",
      "Requirement already satisfied: Jinja2>=2.9 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from bokeh==3.4.1->emp-orderly) (3.1.4)\n",
      "Requirement already satisfied: contourpy>=1.2 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from bokeh==3.4.1->emp-orderly) (1.2.0)\n",
      "Requirement already satisfied: packaging>=16.8 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from bokeh==3.4.1->emp-orderly) (23.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from bokeh==3.4.1->emp-orderly) (10.3.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from bokeh==3.4.1->emp-orderly) (6.0.1)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from bokeh==3.4.1->emp-orderly) (6.4.1)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from bokeh==3.4.1->emp-orderly) (2022.9.0)\n",
      "Collecting eth-abi (from eth-rpc-py==0.1.8post6->emp-orderly)\n",
      "  Using cached eth_abi-5.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting eth-account (from eth-rpc-py==0.1.8post6->emp-orderly)\n",
      "  Using cached eth_account-0.13.4-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting websockets (from eth-rpc-py==0.1.8post6->emp-orderly)\n",
      "  Using cached websockets-13.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pydantic>=2.7.0->emp-orderly-types) (0.6.0)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.7.0->emp-orderly-types)\n",
      "  Using cached pydantic_core-2.23.4-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pydantic>=2.7.0->emp-orderly-types) (4.11.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography==42.0.5->emp-orderly-types) (2.21)\n",
      "Requirement already satisfied: toolz>=0.8.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from cytoolz>=0.10.1->eth-utils==4.1.0->emp-orderly-types) (0.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from Jinja2>=2.9->bokeh==3.4.1->emp-orderly) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.2.2->emp-orderly-types) (1.16.0)\n",
      "Collecting parsimonious<0.11.0,>=0.10.0 (from eth-abi->eth-rpc-py==0.1.8post6->emp-orderly)\n",
      "  Using cached parsimonious-0.10.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting bitarray>=2.4.0 (from eth-account->eth-rpc-py==0.1.8post6->emp-orderly)\n",
      "  Using cached bitarray-2.9.2-cp312-cp312-win_amd64.whl.metadata (35 kB)\n",
      "Collecting eth-keyfile<0.9.0,>=0.7.0 (from eth-account->eth-rpc-py==0.1.8post6->emp-orderly)\n",
      "  Using cached eth_keyfile-0.8.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting eth-keys>=0.4.0 (from eth-account->eth-rpc-py==0.1.8post6->emp-orderly)\n",
      "  Using cached eth_keys-0.5.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting eth-rlp>=2.1.0 (from eth-account->eth-rpc-py==0.1.8post6->emp-orderly)\n",
      "  Using cached eth_rlp-2.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting hexbytes>=1.2.0 (from eth-account->eth-rpc-py==0.1.8post6->emp-orderly)\n",
      "  Using cached hexbytes-1.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting rlp>=1.0.0 (from eth-account->eth-rpc-py==0.1.8post6->emp-orderly)\n",
      "  Using cached rlp-4.0.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting ckzg>=2.0.0 (from eth-account->eth-rpc-py==0.1.8post6->emp-orderly)\n",
      "  Using cached ckzg-2.0.1-cp312-cp312-win_amd64.whl.metadata (718 bytes)\n",
      "Collecting pycryptodome<4,>=3.6.6 (from eth-keyfile<0.9.0,>=0.7.0->eth-account->eth-rpc-py==0.1.8post6->emp-orderly)\n",
      "  Downloading pycryptodome-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: regex>=2022.3.15 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from parsimonious<0.11.0,>=0.10.0->eth-abi->eth-rpc-py==0.1.8post6->emp-orderly) (2023.10.3)\n",
      "Using cached emp_orderly_types-1.0-py3-none-any.whl (5.7 kB)\n",
      "Using cached base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Using cached eth_typing-4.1.0-py3-none-any.whl (14 kB)\n",
      "Using cached eth_utils-4.1.0-py3-none-any.whl (77 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Using cached emp_orderly-1.0-py3-none-any.whl (69 kB)\n",
      "Using cached eth_rpc_py-0.1.8.post6-py3-none-any.whl (63 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.4-cp312-none-win_amd64.whl (1.9 MB)\n",
      "Using cached eth_hash-0.7.0-py3-none-any.whl (8.7 kB)\n",
      "Using cached eth_abi-5.1.0-py3-none-any.whl (29 kB)\n",
      "Using cached eth_account-0.13.4-py3-none-any.whl (581 kB)\n",
      "Using cached websockets-13.1-cp312-cp312-win_amd64.whl (159 kB)\n",
      "Using cached bitarray-2.9.2-cp312-cp312-win_amd64.whl (126 kB)\n",
      "Using cached ckzg-2.0.1-cp312-cp312-win_amd64.whl (98 kB)\n",
      "Using cached eth_keyfile-0.8.1-py3-none-any.whl (7.5 kB)\n",
      "Using cached eth_keys-0.5.1-py3-none-any.whl (21 kB)\n",
      "Using cached eth_rlp-2.1.0-py3-none-any.whl (5.1 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached hexbytes-1.2.1-py3-none-any.whl (5.2 kB)\n",
      "Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB)\n",
      "Using cached rlp-4.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading pycryptodome-3.21.0-cp36-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.8 MB 1.3 MB/s eta 0:00:02\n",
      "    --------------------------------------- 0.0/1.8 MB 1.3 MB/s eta 0:00:02\n",
      "    --------------------------------------- 0.0/1.8 MB 1.3 MB/s eta 0:00:02\n",
      "    --------------------------------------- 0.0/1.8 MB 1.3 MB/s eta 0:00:02\n",
      "    --------------------------------------- 0.0/1.8 MB 151.3 kB/s eta 0:00:12\n",
      "    --------------------------------------- 0.0/1.8 MB 151.3 kB/s eta 0:00:12\n",
      "    --------------------------------------- 0.0/1.8 MB 151.3 kB/s eta 0:00:12\n",
      "    --------------------------------------- 0.0/1.8 MB 151.3 kB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.1/1.8 MB 142.2 kB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.1/1.8 MB 142.2 kB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.1/1.8 MB 142.2 kB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.1/1.8 MB 126.7 kB/s eta 0:00:14\n",
      "   -- ------------------------------------- 0.1/1.8 MB 154.0 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.1/1.8 MB 177.2 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.1/1.8 MB 180.2 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.1/1.8 MB 187.0 kB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.2/1.8 MB 222.9 kB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.2/1.8 MB 222.9 kB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.2/1.8 MB 222.9 kB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 0.2/1.8 MB 206.3 kB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 0.2/1.8 MB 218.4 kB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 0.2/1.8 MB 222.1 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.2/1.8 MB 228.7 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.2/1.8 MB 228.7 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.3/1.8 MB 234.7 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.3/1.8 MB 249.1 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 0.3/1.8 MB 251.3 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 0.3/1.8 MB 262.1 kB/s eta 0:00:06\n",
      "   ------- -------------------------------- 0.3/1.8 MB 277.2 kB/s eta 0:00:06\n",
      "   -------- ------------------------------- 0.4/1.8 MB 283.1 kB/s eta 0:00:06\n",
      "   -------- ------------------------------- 0.4/1.8 MB 284.2 kB/s eta 0:00:06\n",
      "   --------- ------------------------------ 0.4/1.8 MB 301.2 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.4/1.8 MB 301.8 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.5/1.8 MB 306.2 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.5/1.8 MB 314.0 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 320.8 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 327.6 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.6/1.8 MB 337.0 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.6/1.8 MB 337.0 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.6/1.8 MB 336.7 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 0.6/1.8 MB 342.1 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 0.6/1.8 MB 344.8 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 0.6/1.8 MB 350.2 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 0.6/1.8 MB 350.2 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 0.7/1.8 MB 343.4 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 0.7/1.8 MB 350.8 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.7/1.8 MB 355.6 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 0.7/1.8 MB 357.4 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 364.0 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 370.3 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.8/1.8 MB 376.5 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.9/1.8 MB 380.3 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.9/1.8 MB 379.6 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.9/1.8 MB 379.6 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.9/1.8 MB 379.6 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.9/1.8 MB 379.6 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.9/1.8 MB 367.4 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 1.0/1.8 MB 379.1 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 1.0/1.8 MB 382.6 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.0/1.8 MB 385.3 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.0/1.8 MB 388.4 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 389.3 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.1/1.8 MB 394.7 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.1/1.8 MB 396.9 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.1/1.8 MB 396.1 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.1/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.2/1.8 MB 398.9 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.2/1.8 MB 401.6 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.2/1.8 MB 400.8 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.2/1.8 MB 400.8 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.2/1.8 MB 401.9 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.4/1.8 MB 358.7 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.4/1.8 MB 359.6 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.4/1.8 MB 359.6 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 1.5/1.8 MB 374.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.5/1.8 MB 375.2 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.5/1.8 MB 374.8 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.5/1.8 MB 377.0 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.8 MB 377.7 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 380.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 380.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 380.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 380.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 380.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 380.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 380.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 364.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.7/1.8 MB 373.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.7/1.8 MB 373.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.7/1.8 MB 373.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.7/1.8 MB 373.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.7/1.8 MB 365.3 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.7/1.8 MB 364.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.7/1.8 MB 363.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.7/1.8 MB 363.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.8/1.8 MB 362.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.8/1.8 MB 361.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 361.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 365.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 315.2 kB/s eta 0:00:00\n",
      "Installing collected packages: ckzg, bitarray, websockets, requests, python-dotenv, pydantic-core, pycryptodome, parsimonious, hexbytes, h11, eth-typing, eth-hash, base58, pydantic, httpcore, eth-utils, rlp, httpx, eth-keys, eth-abi, eth-rlp, eth-keyfile, emp-orderly-types, eth-account, eth-rpc-py, emp-orderly\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.2\n",
      "    Uninstalling requests-2.32.2:\n",
      "      Successfully uninstalled requests-2.32.2\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 0.21.0\n",
      "    Uninstalling python-dotenv-0.21.0:\n",
      "      Successfully uninstalled python-dotenv-0.21.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.6\n",
      "    Uninstalling pydantic_core-2.14.6:\n",
      "      Successfully uninstalled pydantic_core-2.14.6\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.3\n",
      "    Uninstalling pydantic-2.5.3:\n",
      "      Successfully uninstalled pydantic-2.5.3\n",
      "Successfully installed base58-2.1.1 bitarray-2.9.2 ckzg-2.0.1 emp-orderly-1.0 emp-orderly-types-1.0 eth-abi-5.1.0 eth-account-0.13.4 eth-hash-0.7.0 eth-keyfile-0.8.1 eth-keys-0.5.1 eth-rlp-2.1.0 eth-rpc-py-0.1.8.post6 eth-typing-4.1.0 eth-utils-4.1.0 h11-0.14.0 hexbytes-1.2.1 httpcore-1.0.6 httpx-0.27.0 parsimonious-0.10.0 pycryptodome-3.21.0 pydantic-2.9.2 pydantic-core-2.23.4 python-dotenv-1.0.1 requests-2.31.0 rlp-4.0.1 websockets-13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install emp-orderly-types emp-orderly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b20096-8d8b-46fb-83d0-bc1cea5abeaa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\chelo\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting google-cloud-storage\n",
      "  Using cached google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-auth<3.0dev,>=2.26.1 (from google-cloud-storage)\n",
      "  Using cached google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage)\n",
      "  Using cached google_api_core-2.20.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage)\n",
      "  Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage)\n",
      "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from google-cloud-storage) (2.31.0)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage)\n",
      "  Using cached google_crc32c-1.6.0-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage)\n",
      "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (3.20.3)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage)\n",
      "  Using cached proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.6.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.8)\n",
      "Using cached google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
      "Using cached google_api_core-2.20.0-py3-none-any.whl (142 kB)\n",
      "Using cached google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Using cached google_crc32c-1.6.0-cp312-cp312-win_amd64.whl (33 kB)\n",
      "Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Using cached proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: rsa, proto-plus, googleapis-common-protos, google-crc32c, google-resumable-media, google-auth, google-api-core, google-cloud-core, google-cloud-storage\n",
      "Successfully installed google-api-core-2.20.0 google-auth-2.35.0 google-cloud-core-2.4.1 google-cloud-storage-2.18.2 google-crc32c-1.6.0 google-resumable-media-2.7.2 googleapis-common-protos-1.65.0 proto-plus-1.24.0 rsa-4.9\n",
      "Requirement already satisfied: google-auth in c:\\users\\chelo\\anaconda3\\lib\\site-packages (2.35.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from google-auth) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from google-auth) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from google-auth) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth) (0.4.8)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\chelo\\anaconda3\\lib\\site-packages (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from aiohttp) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from aiohttp) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from aiohttp) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from aiohttp) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from aiohttp) (1.9.3)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp) (3.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-storage\n",
    "!pip install google-auth\n",
    "!pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6d959db-a611-4d02-9621-8cff352dda84",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ta\n",
      "  Using cached ta-0.11.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from ta) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from ta) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas->ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas->ta) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas->ta) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\n",
      "Installing collected packages: ta\n",
      "Successfully installed ta-0.11.0\n",
      "Collecting pandas-ta\n",
      "  Using cached pandas_ta-0.3.14b0-py3-none-any.whl\n",
      "Requirement already satisfied: pandas in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas-ta) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas->pandas-ta) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas->pandas-ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas->pandas-ta) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from pandas->pandas-ta) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chelo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->pandas-ta) (1.16.0)\n",
      "Installing collected packages: pandas-ta\n",
      "Successfully installed pandas-ta-0.3.14b0\n"
     ]
    }
   ],
   "source": [
    "!pip install ta\n",
    "!pip install pandas-ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69d42ce-41d3-48f4-8826-2e12aabcab09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"f0836ef5-b11f-4f51-a17f-b71e229816fc\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "'use strict';\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded(error = null) {\n",
       "    const el = document.getElementById(\"f0836ef5-b11f-4f51-a17f-b71e229816fc\");\n",
       "    if (el != null) {\n",
       "      const html = (() => {\n",
       "        if (typeof root.Bokeh === \"undefined\") {\n",
       "          if (error == null) {\n",
       "            return \"BokehJS is loading ...\";\n",
       "          } else {\n",
       "            return \"BokehJS failed to load.\";\n",
       "          }\n",
       "        } else {\n",
       "          const prefix = `BokehJS ${root.Bokeh.version}`;\n",
       "          if (error == null) {\n",
       "            return `${prefix} successfully loaded.`;\n",
       "          } else {\n",
       "            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n",
       "          }\n",
       "        }\n",
       "      })();\n",
       "      el.innerHTML = html;\n",
       "\n",
       "      if (error != null) {\n",
       "        const wrapper = document.createElement(\"div\");\n",
       "        wrapper.style.overflow = \"auto\";\n",
       "        wrapper.style.height = \"5em\";\n",
       "        wrapper.style.resize = \"vertical\";\n",
       "        const content = document.createElement(\"div\");\n",
       "        content.style.fontFamily = \"monospace\";\n",
       "        content.style.whiteSpace = \"pre-wrap\";\n",
       "        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n",
       "        content.textContent = error.stack ?? error.toString();\n",
       "        wrapper.append(content);\n",
       "        el.append(wrapper);\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(() => display_loaded(error), 100);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      try {\n",
       "            for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "\n",
       "      } catch (error) {display_loaded(error);throw error;\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"f0836ef5-b11f-4f51-a17f-b71e229816fc\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"f0836ef5-b11f-4f51-a17f-b71e229816fc\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"f0836ef5-b11f-4f51-a17f-b71e229816fc\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from emp_orderly import (\n",
    "    Strategy, EmpOrderly,\n",
    "    crossover, plot_heatmaps,\n",
    "    EMA, SMA, SLOPE, CHOP,\n",
    "    EmpyrealOrderlySDK,\n",
    ")\n",
    "from emp_orderly_types import PerpetualAssetType, Interval, OrderType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a1d695-c5d5-4b2c-83ae-16dace57e73d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eth_typeshed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meth_rpc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01memp_orderly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monboarding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\emp_orderly\\onboarding\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcreate_account\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_account\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madd_access_key\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_access_key\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeposit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deposit\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfaucet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m request_testnet_funds\n\u001b[0;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_access_key\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_account\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_testnet_funds\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\emp_orderly\\onboarding\\deposit.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meth_rpc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_checksum\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meth_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HexStr\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meth_typeshed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merc20\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ERC20, ApproveRequest\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeposit\u001b[39m(wallet: PrivateKeyWallet, deposit_amount: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000\u001b[39m, network: \u001b[38;5;28mtype\u001b[39m[Network] \u001b[38;5;241m=\u001b[39m ArbitrumSepolia) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HexStr:\n\u001b[0;32m      9\u001b[0m     set_default_network(network)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'eth_typeshed'"
     ]
    }
   ],
   "source": [
    "from eth_rpc import *\n",
    "from emp_orderly.onboarding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab29c88-f673-4899-86d0-a2cecd28bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emp_orderly import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4668ebd5-6e05-465c-9cff-33004495f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "import uuid\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7e7db62d-44bc-4cb4-891c-8bc82754e722",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from nacl.signing import SigningKey\n",
    "from base58 import b58encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37942654-ba8d-4f0b-a268-d33cf6ea278f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Setting up your Orderly Account for SDK access\n",
    "\n",
    "# create a new wallet\n",
    "wallet = PrivateKeyWallet.create_new()\n",
    "# print your private key so you can write it down for use later\n",
    "print(wallet.address, wallet.private_key)\n",
    "\n",
    "# create a new account on orderly\n",
    "acct = await create_account(wallet)\n",
    "\n",
    "#COPY YOUR ADDRESS AND PRIVATE KEY BELOW : Store somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8814afb2-30b5-468c-bc91-03315e35cb18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acct' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrderly Acct: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macct\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'acct' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Orderly Acct: {acct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "26155c00-8a10-4b3e-a6ac-ea767dd211d0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "private_key_hex = wallet.private_key.removeprefix(\"0x\")\n",
    "signing_key = SigningKey(bytes.fromhex(private_key_hex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d359fd84-bc12-40de-9de1-d58a8061b063",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "public_key = signing_key.verify_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e4a7d8-78cf-4352-9c02-63a5cc1ba814",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "key_bytes = public_key.encode()  # nacl uses encode() to get the public key bytes\n",
    "orderly_key = \"ed25519:%s\" % b58encode(key_bytes).decode(\"utf-8\")\n",
    "\n",
    "# register your new orderly key as a signer for your wallet address\n",
    "result = await add_access_key(wallet, orderly_key)\n",
    "\n",
    "print(f\"Orderly key: {orderly_key}\")\n",
    "\n",
    "# Copy your Orderly Key too Incase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c8384-ed4a-4bde-a091-2a90498ae82e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# get some testnet USDC from the faucet ($1000)\n",
    "await faucet(wallet)\n",
    "\n",
    "# deposit this testnet USDC to Orderly (NOTE: requires some ETH for gas - GET Some Eth Sepolia First in Wallet bfr running )\n",
    "# from here: https://faucets.chain.link/sepolia --- THEN uncomment & deposit\n",
    "#await deposit(wallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a8bae-5aae-43a9-8d58-75c35f31f727",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wallet = {\n",
    "    \"private_key\": \"write your private key here\",\n",
    "    \"address\": \"write your address here\"\n",
    "}\n",
    "\n",
    "account_id = \"write your acct here\"\n",
    "\n",
    "# Now use the wallet dictionary\n",
    "sdk = EmpyrealOrderlySDK(pvt_hex=wallet['private_key'], account_id=account_id, is_testnet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97923bf3-d6fd-42ae-bdc2-6a9ac46185b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet = {\n",
    "    \"private_key\": \"30e6cd50e6f7110d63e1fd83a68d0a46a8d11932635fae36642a0c68ef72fe28\",\n",
    "    \"address\": \"0xEE48C329AAEB8Db0d2b4C577d36F69aAF51AbB69\"\n",
    "}\n",
    "\n",
    "account_id = \"0xeffefc0efde28f5230a962c97a9e6badbae46c407c75aa4749063c5bebbe909b\"\n",
    "\n",
    "# Now use the wallet dictionary\n",
    "sdk = EmpyrealOrderlySDK(pvt_hex=wallet['private_key'], account_id=account_id, is_testnet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ee61b8a-95ff-4dea-b596-29e6dad23fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ACCOUNT_ID'] = account_id\n",
    "os.environ['PVT_HEX'] = \"30e6cd50e6f7110d63e1fd83a68d0a46a8d11932635fae36642a0c68ef72fe28\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b4690f2-ec97-4728-bd0d-0959145ca0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = {\n",
    "    \"type\": \"service_account\",\n",
    "    \"project_id\": \"agent-xtransformers\",\n",
    "    \"private_key_id\": \"110f9fccdcb1a0698f5481b6830d2a1fb44119b1\",\n",
    "    \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCeDcwe5lI0mnpw\\n3Xn98nKYiKgUjwfaPrHO3Nw9f0UExA+KmOoiiKRvaXeJf0laebGfLXEcYfkSSbvs\\nzc3BD6n1r8Ks/VxHe8Tnot+H7EpX7lYdjIyxxQqMzqmTVUavcbJZG57/K8N3IdmP\\nh1Q03XYU5veq4Cvd0kLAjnUz5H9yetA8iC476pAYNX8enpjQKP/9CCmpC1lS38yM\\neCEOtYQlkEwsBTJzASumsdAEP745VhnsyrBmUHwzpw7WNlpehbTuOwND7kbqa8HR\\nNo0FUml7nbQhCmqNboG67XYtFzcMyRVIm5b1ZNZZgtMXuUYTcPjpNpfbfxKAU1gi\\n0R54ygdrAgMBAAECggEAEmTSq4nsaTjNJRNxXg94LK5CuVnH9Ss0sDld3D5SfvJ+\\nSIfxP6GdWWXxxmus0r204Sx9rGrufKVeHHn7BwvWoMQaqN03fw41ZSu8Teo+4KrZ\\nFMlFmm6vAqIOdBoJhuN5eQtQ3qtuLRAgbKa4MwrO8jHLAvThxgfxQs2RcD+YYW8g\\npKYYuCaMm7iWx+RMTmjhcdUwXLEy1aosxHjalnr3jNjqPoEXZe+3f2jy2ASOg4Rh\\nZ+rgLJPk4JYGCeXQSiHWVoiK21N9os0s4/ZeAyH9I9l+aOWjnIDnhRoyAzSILgOD\\nKrY1RC/n5HzYh/9malxcZBKX5HF+IBAjOeVQMUOkMQKBgQDVPeuw3oNQpVBT6hqd\\na/1Z0op2OhrJLbzxgzIpMKnLKQWSbTifDTDdbtkKcgZS5JTmFVyLXR6sM/8qP0QU\\nb6GF3rDoL8MnvAMzFXpt2dvAI7Sj5uvA00qGF329mpNylyeDcfqEgreDY/SuxhVH\\n6U9V9oi/LNDlQhR72T1v8Q0w0wKBgQC9vvsY1Fk5zQKwaInh/g9CDSJMBhBdbtgx\\nT16i79EMzfAn5DZ5/PPv3N7n15bybXZJv9uymQSm/+18VujNM6llUqPNrrCcZwFb\\nCeYlXM3SECkp7Leikq81rAnhiq0BfvBfyRcFJJliQGn1TLV3YC2x1hUPUyta33MC\\nwHIlu81wCQKBgQCrlygRKvx/6Ia6/6ZrBnrXzJOejyL+v89KiEfU3VPEJz5UlY76\\nbaLkjE4aGab9DPLEMmxFuKj16OFrHX2q9CkFkCzKqaRgVOo+MQpTWvt5oUG6ohcT\\nEvLk9AI6kCgWDYu+Oflcp9MD52r9OGfnddZhVgCz1VxDHulcv3KwoUf8AQKBgDrC\\nVLH4uHTc1tNYXDKe4Yy70n4mdpToiYyjnpPonh1P/Ontky0tt0D1bhXvvm/uk+38\\nuwVQu48XvCyAIXHCaNfWwqEkUs7sWxAdPaceWSKPHKA+DRQMRrPhReIRdsf6zmdr\\nN3TBQ7qYZfevvJZuM1haCoWHZOqsPcqBXBfxU4o5AoGAFIwU7oxGmrQpDam5KpVA\\n59cKVcwUQSjljYavcRcgMj7CclGAaMhLQkdRNziZltVl7Nd5bRvDWXgnwzbVrAmp\\nm7EPxkHIL0P2xofAx+Z1aBXz636fzSsEgBLEOSvWswYDXtY1VeswHMToPWHvA/ZB\\n+GEf0Md05HH5Tf5lEaAGBM4=\\n-----END PRIVATE KEY-----\\n\",\n",
    "    \"client_email\": \"firestore-service-account@agent-xtransformers.iam.gserviceaccount.com\",\n",
    "    \"client_id\": \"108505861646499193215\",\n",
    "    \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "    \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "    \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "    \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/firestore-service-account%40agent-xtransformers.iam.gserviceaccount.com\",\n",
    "    \"universe_domain\": \"googleapis.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfb4cf52-0c5b-4928-9dee-8f888441b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the lock file exists\n",
    "def check_lock():\n",
    "    storage_client = storage.Client.from_service_account_info(key_path)\n",
    "    bucket_name = \"tradingaccess\"\n",
    "    lock_filename = \"strategy.lock\"\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(lock_filename)\n",
    "    \n",
    "    # Attempt to access the lock file in the bucket\n",
    "    try:\n",
    "        blob = storage_client.bucket(bucket_name).blob(lock_filename)\n",
    "        return blob.exists()  # Returns True if the lock file exists\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking lock: {e}\")\n",
    "        return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f7a8df2-85c5-490e-8f2c-f673aa482b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a lock file\n",
    "def create_lock():\n",
    "    storage_client = storage.Client.from_service_account_info(key_path)\n",
    "    bucket_name = \"tradingaccess\"\n",
    "    lock_filename = \"strategy.lock\"\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(lock_filename)\n",
    "\n",
    "    # Create the lock file\n",
    "    blob.upload_from_string(\"locked\")\n",
    "    print(\"Lock file created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5efc03ca-2799-43a2-a132-37af44f522af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to release the lock\n",
    "def release_lock():\n",
    "    storage_client = storage.Client.from_service_account_info(key_path)  # GCS client\n",
    "    bucket_name = \"tradingaccess\"\n",
    "    lock_filename = \"strategy.lock\"\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(lock_filename)\n",
    "\n",
    "    # Delete the lock file\n",
    "    if blob.exists():\n",
    "        blob.delete()\n",
    "        print(\"Lock file deleted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6b7f287-c2bc-478d-86d6-12148f99fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIEventDrivenStrategy(Strategy):\n",
    "    # Define class variables for parameters\n",
    "    risk: float = 0.5\n",
    "    acct_balance: float = 10000\n",
    "    max_drawdown: float = 50\n",
    "    jdk: any = None\n",
    "    lock_duration_minutes = 10\n",
    "\n",
    "    def __init__(self, broker, data, params):\n",
    "        super().__init__(broker, data, params)\n",
    "        self.broker = broker\n",
    "        self.params = params\n",
    "        self.risk = params.get(\"risk\", self.risk)\n",
    "        self.acct_balance = params.get(\"acct_balance\", self.acct_balance)\n",
    "        self.max_drawdown = params.get(\"max_drawdown\", self.max_drawdown)\n",
    "        self.jdk = params.get(\"jdk\", self.jdk)\n",
    "\n",
    "        self.previous_action = None\n",
    "        self.returns = []\n",
    "        self.pnl_history = []\n",
    "        self.trade_count = 0\n",
    "        self.cumulative_loss = Decimal('0')\n",
    "        self.min_cumulative_loss_threshold = Decimal('15')\n",
    "        self.quote_tick = Decimal('0.01')\n",
    "        self.stop_trading = False\n",
    "        self.current_price = None\n",
    "        self.last_prices = []\n",
    "        self.last_directions = []\n",
    "        self.trade_thresholds = {\n",
    "            'wide_movement': 0.005,  # 5% threshold for wide movements\n",
    "            'small_movement': 0.0005   # 1% threshold for small movements\n",
    "        }\n",
    "        self.loop = asyncio.get_event_loop()\n",
    "        self.task = None  # Track the running task\n",
    "        print('Initialized AIEventDrivenStrategy')\n",
    "\n",
    "    def init(self):\n",
    "        print('Strategy initialization complete.')\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"\n",
    "        The core logic that runs on each iteration of new market data.\n",
    "        Restart the loop if it has been stopped or canceled.\n",
    "        \"\"\"\n",
    "        if self.stop_trading:\n",
    "            self.stop_trading = False  # Reset stop flag for restarting\n",
    "            print('Restarting the trading loop...')\n",
    "\n",
    "        if not self.task or self.task.done():\n",
    "            # Only start a new task if one isn't already running\n",
    "            self.task = self.loop.create_task(self.run_trading_loop())\n",
    "        print('Executing next iteration of strategy.')\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"\n",
    "        Set the flag to stop the trading loop and cancel any running task.\n",
    "        \"\"\"\n",
    "        self.stop_trading = True\n",
    "        if self.task:\n",
    "            self.task.cancel()  # Cancel the running task\n",
    "            print('Trading will stop immediately.')\n",
    "\n",
    "    async def run_trading_loop(self):\n",
    "        \"\"\"\n",
    "        Continuously run the trading logic at 5-minute intervals.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            while not self.stop_trading:\n",
    "                await self.trade_logic()  # Execute trading logic\n",
    "                print(\"Waiting for next iteration in 5 minutes...\")\n",
    "                await asyncio.sleep(5 * 60)  # Wait for 5 minutes before repeating\n",
    "\n",
    "        except asyncio.CancelledError:\n",
    "            print(\"Trading loop was cancelled.\")\n",
    "            raise\n",
    "        \n",
    "        print(\"Trading loop exited.\")\n",
    "\n",
    "    async def trade_logic(self):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Starting trade logic...\")  # Debug statement at the start\n",
    "        \n",
    "        try:\n",
    "            # Update price data before assessing volatility\n",
    "            await self.add_price()\n",
    "\n",
    "            # Step 1: Assess volatility\n",
    "            volatility_status = await self.assess_volatility()\n",
    "\n",
    "            # Step 2: Fetch market prediction\n",
    "            prediction = await self.fetch_cloud_prediction()\n",
    "            if prediction is None:\n",
    "                print(\"No prediction received, skipping trade.\")\n",
    "                trade_executed = False\n",
    "                await self.track_metrics(trade_executed)  # Still track metrics\n",
    "                await self.monitor_open_trades()\n",
    "                return\n",
    "\n",
    "            print(\"Predicted Price:\", prediction)\n",
    "\n",
    "            # Step 3: Check market sentiment and current price\n",
    "            sentiment, sentiment_score, atr = await self.market_sentiment()\n",
    "            \n",
    "            indicators = await self.fetch_technical_indicators()\n",
    "\n",
    "            # Step 4: Check account status\n",
    "            account_status = await self.check_account_status(sentiment)\n",
    "            if account_status is None:\n",
    "                print(\"Could not retrieve account status, skipping trade.\")\n",
    "                return\n",
    "\n",
    "            incomplete_orders = account_status.get('incomplete_orders', 0)\n",
    "            free_collateral = account_status.get('free_collateral', 0)\n",
    "            position_qty = account_status.get('position_qty', 0)\n",
    "            print(\"Free Collateral:\", free_collateral)\n",
    "\n",
    "            # Step 5: Check if volatility favors holding\n",
    "            if volatility_status == \"volatile\":\n",
    "                print(\"Holding: High volatility detected, avoiding trades.\")\n",
    "                await self.monitor_open_trades()\n",
    "                return\n",
    "            elif volatility_status == \"small_movement\":\n",
    "                print(\"Holding: Small price movement detected, avoiding trades.\")\n",
    "                await self.monitor_open_trades()\n",
    "                return\n",
    "\n",
    "            margin_limits = 200\n",
    "            if incomplete_orders >= 2:\n",
    "                print(\"Pending orders must be filled or closed to prevent overtrading.\")\n",
    "                # await jdk.close_position(PerpetualAssetType.ETH)\n",
    "                await self.monitor_open_trades()\n",
    "                return\n",
    "            if free_collateral < margin_limits:\n",
    "                print(\"Insufficient free collateral to place new trades.\")\n",
    "                return\n",
    "\n",
    "            print(\"incomplete order\", incomplete_orders)\n",
    "\n",
    "            # Step 6: Calculate price difference and decision making\n",
    "            try:\n",
    "                price_diff = (prediction - self.current_price)\n",
    "                print(\"Price Diff [Prediction & Current]:\", price_diff)\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating price_diff: {e}\")\n",
    "                return\n",
    "\n",
    "            await self.monitor_open_trades()\n",
    "\n",
    "            # Step 7: Get dynamic stop loss and take profit levels\n",
    "            stop_loss, take_profit = self.calculate_dynamic_levels(sentiment_score, atr)\n",
    "\n",
    "            # Calculate position size\n",
    "            position_size = await self.calculate_position_size(sentiment_score)\n",
    "\n",
    "            # Step 8: Decision making based on price difference and sentiment\n",
    "            trade_executed = False\n",
    "\n",
    "            current_positions = await jdk.positions()\n",
    "\n",
    "            # await jdk.close_position(PerpetualAssetType.ETH)\n",
    "            \n",
    "            eth_position = next((pos for pos in current_positions.rows if pos.symbol == PerpetualAssetType.ETH), None)\n",
    "            # Check if position size exceeds limits before executing a trade\n",
    "            if eth_position:\n",
    "                # Check for long position (positive value)\n",
    "                if eth_position.position_qty >= 0.05:\n",
    "                    #await jdk.close_position(PerpetualAssetType.ETH)\n",
    "                    await self.monitor_open_trades()\n",
    "                    print(f\"Position size is too large (Long: {eth_position.position_qty}). Closing the position.\")\n",
    "                    #return\n",
    "                # Check for pending long orders\n",
    "                elif eth_position.pending_long_qty >= 0.05:\n",
    "                    print(f\"Long size is too large (Pending Long: {eth_position.pending_long_qty}). Not opening a new buy trade.\")\n",
    "                    return\n",
    "                # Check for short position (negative value)\n",
    "                elif eth_position.position_qty <= -0.05:\n",
    "                    #await jdk.close_position(PerpetualAssetType.ETH)\n",
    "                    await self.monitor_open_trades()\n",
    "                    print(f\"Shorting size is too large (Short: {eth_position.position_qty}). Closing the position.\")\n",
    "                    #return\n",
    "                # Check for pending short orders\n",
    "                elif eth_position.pending_short_qty <= -0.1:\n",
    "                    print(f\"Shorting size is too large (Pending Short: {eth_position.pending_short_qty}). Not opening a new sell trade.\")\n",
    "                    return\n",
    "\n",
    "            threshold_above = 10  # 1% above\n",
    "            threshold_below = -2  # 0.5% below\n",
    "            threshold_above_bearish = 2  # 0.5% above for bearish conditions\n",
    "            threshold_below_bearish = -10  # 1% below for bearish conditions\n",
    "            confidence_bullish = 3\n",
    "            confidence_bearish = -3\n",
    "            \n",
    "            # Retrieve the EMA/SMA values for both 5m and 15m timeframes\n",
    "            ema_5 = indicators['ema_5']\n",
    "            ema_12 = indicators['ema_12']\n",
    "            ema_5_15m = indicators['ema_5_15m']\n",
    "            ema_12_15m = indicators['ema_12_15m']\n",
    "        \n",
    "            # Determine short-term (5m) and mid-term (15m) trends\n",
    "            is_bullish_5m = ema_5 > ema_12\n",
    "            is_bearish_5m = ema_5 < ema_12\n",
    "            is_bullish_15m = ema_5_15m > ema_12_15m\n",
    "            is_bearish_15m = ema_5_15m < ema_12_15m\n",
    "\n",
    "            if threshold_below < price_diff < threshold_above and sentiment == 'bullish':\n",
    "                await self.handle_buy_trade(sentiment_score, stop_loss, take_profit, position_size)\n",
    "                trade_executed = True\n",
    "            elif threshold_below_bearish < price_diff < threshold_above_bearish and sentiment == 'bearish':\n",
    "                await self.handle_sell_trade(sentiment_score, stop_loss, take_profit, position_size)\n",
    "                trade_executed = True\n",
    "            elif price_diff > confidence_bullish and sentiment == 'neutral':\n",
    "                await self.handle_buy_trade(sentiment_score, stop_loss, take_profit, position_size)\n",
    "                trade_executed = True\n",
    "            elif price_diff > confidence_bearish and sentiment == 'neutral':\n",
    "                await self.handle_sell_trade(sentiment_score, stop_loss, take_profit, position_size)\n",
    "                trade_executed = True\n",
    "            # FALLBACK: Handle overlaps between model prediction and sentiment\n",
    "            else:\n",
    "                # Case where the model and sentiment disagree (overlap)\n",
    "                if (price_diff > confidence_bullish and sentiment == 'bearish') or (price_diff < confidence_bearish and sentiment == 'bullish'):\n",
    "                    print(\"Overlap detected between model and sentiment. Falling back to 5m and 15m alignment.\")\n",
    "        \n",
    "                    # Use the 5m and 15m EMA/SMA alignment to resolve the conflict\n",
    "                    if is_bullish_5m and is_bullish_15m:\n",
    "                        print(\"Both 5m and 15m align as bullish. Executing BUY trade.\")\n",
    "                        await self.handle_buy_trade(sentiment_score, stop_loss, take_profit, position_size)\n",
    "                        trade_executed = True\n",
    "        \n",
    "                    elif is_bearish_5m and is_bearish_15m:\n",
    "                        print(\"Both 5m and 15m align as bearish. Executing SELL trade.\")\n",
    "                        await self.handle_sell_trade(sentiment_score, stop_loss, take_profit, position_size)\n",
    "                        trade_executed = True\n",
    "        \n",
    "                    else:\n",
    "                        print(\"5m and 15m do not align. Hold: No trade executed.\")\n",
    "        \n",
    "                else:\n",
    "                    print(\"Hold: Conditions do not favor a trade.\")\n",
    "            # else:\n",
    "            #     print(\"Hold: Conditions do not favor a trade.\")\n",
    "            \n",
    "            # Step 9: Track metrics after decision\n",
    "\n",
    "            await self.track_metrics(trade_executed, position_size)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in trade logic: {e}\")  # Log the error\n",
    "\n",
    "\n",
    "    # Add price and also track direction of movement\n",
    "    async def add_price(self):\n",
    "        price = await self.fetch_current_price()\n",
    "    \n",
    "        # Determine if it's up or down based on the last price\n",
    "        if len(self.last_prices) > 0:\n",
    "            last_price = self.last_prices[-1]\n",
    "            price_direction = \"up\" if price > last_price else \"down\" if price < last_price else \"same\"\n",
    "            self.last_directions.append(price_direction)\n",
    "    \n",
    "        # Store the new price\n",
    "        self.last_prices.append(price)\n",
    "    \n",
    "        # Limit to 3 prices for the window\n",
    "        if len(self.last_prices) > 3:\n",
    "            self.last_prices.pop(0)\n",
    "            self.last_directions.pop(0)  # Also maintain the same length for directions\n",
    "    \n",
    "        print(self.last_prices, self.last_directions)\n",
    "\n",
    "\n",
    "    # Assess volatility based on both price range and direction switches\n",
    "    async def assess_volatility(self):\n",
    "        if len(self.last_prices) < 3 or len(self.last_directions) < 2:\n",
    "            return \"not_enough_data\"\n",
    "    \n",
    "        avg_price = sum(self.last_prices) / len(self.last_prices)\n",
    "        price_range = max(self.last_prices) - min(self.last_prices)\n",
    "        price_movement_pct = price_range / avg_price\n",
    "    \n",
    "        # Count how many times the price direction changes in the 3-price window\n",
    "        direction_changes = 0\n",
    "        for i in range(1, len(self.last_directions)):\n",
    "            if self.last_directions[i] != self.last_directions[i-1] and self.last_directions[i] != \"same\":\n",
    "                direction_changes += 1\n",
    "    \n",
    "        # If price moves up and down (direction change), and the range is wide, it's volatile\n",
    "        if direction_changes >= 2 and price_movement_pct > self.trade_thresholds['wide_movement']:\n",
    "            return \"volatile\"  # Swings in both directions\n",
    "        elif price_movement_pct > self.trade_thresholds['wide_movement']:\n",
    "            return \"trending\"  # Price is moving strongly in one direction\n",
    "        elif price_movement_pct < self.trade_thresholds['small_movement']:\n",
    "            return \"small_movement\"  # Price is moving within a tight range\n",
    "        else:\n",
    "            return \"normal\"\n",
    "\n",
    "\n",
    "\n",
    "    async def fetch_cloud_prediction(self):\n",
    "        \"\"\"\n",
    "        Fetch prediction and send OHLCV data to cloud function.\n",
    "        \"\"\"\n",
    "        ohlcv_data = await jdk.get_ohlcv(\n",
    "            asset=PerpetualAssetType.ETH,\n",
    "            resolution=Interval.five_minute,\n",
    "            start_days_behind=2.5 / 24,  # 2.5 hours ago\n",
    "            end_days_behind=0  # Now\n",
    "        )\n",
    "        \n",
    "        self.current_price = ohlcv_data['close'].iloc[-1]\n",
    "        print(f\"Current price (ETH): {self.current_price}\")\n",
    "\n",
    "        \n",
    "        await self.send_ohlcv_to_cloud(ohlcv_data)\n",
    "        \n",
    "        # Fetch the prediction from your Vertex AI model\n",
    "        prediction = await self.get_prediction_from_vertex_ai()\n",
    "    \n",
    "        return prediction\n",
    "\n",
    "    async def send_ohlcv_to_cloud(self, ohlcv_data):\n",
    "        \n",
    "        # Continue with your OHLCV data processing\n",
    "        ohlcv_data = ohlcv_data.drop(columns=['volume_asset'])\n",
    "        ohlcv_data.reset_index(inplace=True)\n",
    "\n",
    "        last_five_prices = ohlcv_data['close'].iloc[-5:]  # Get the last 5 'close' prices\n",
    "        # print(\"Last five close prices:\", last_five_prices.tolist())\n",
    "    \n",
    "        ohlcv_data_dict = ohlcv_data.to_dict(orient='records')\n",
    "        for record in ohlcv_data_dict:\n",
    "            for key, value in record.items():\n",
    "                if isinstance(value, pd.Timestamp):\n",
    "                    record[key] = int(value.timestamp() * 1000)  # Convert to milliseconds\n",
    "    \n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.post(\n",
    "                'https://us-central1-agent-xtransformers.cloudfunctions.net/getOrderlyKlines/getOrderlyKlines',\n",
    "                json=ohlcv_data_dict\n",
    "            ) as resp:\n",
    "                if resp.status == 200:\n",
    "                    print(\"Data successfully sent to cloud function.\")\n",
    "                else:\n",
    "                    print(f\"Failed to send data: {resp.status}\")\n",
    "\n",
    "            await asyncio.sleep(12)\n",
    "\n",
    "\n",
    "\n",
    "    async def get_prediction_from_vertex_ai(self):\n",
    "        \"\"\"\n",
    "        Fetch the prediction from the Vertex AI model cloud function.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.get('https://us-central1-agent-xtransformers.cloudfunctions.net/returnPrediction') as resp:\n",
    "                    if resp.status == 200:\n",
    "                        prediction = await resp.json()\n",
    "                        # Extract the value and ensure it's not None\n",
    "                        prediction_value = prediction.get('currentVariable', self.current_price)  # Fall back to self.current_price if key is missing\n",
    "                        #print(\"prediction value:\", prediction_value)\n",
    "        \n",
    "                        if prediction_value is not None:  # Explicit check for None\n",
    "                            try:\n",
    "                                prediction = float(prediction_value)  # Convert to float\n",
    "                                return prediction\n",
    "                            except ValueError:\n",
    "                                print(f\"Failed to convert prediction to float: {prediction_value}\")\n",
    "                                return self.current_price  # Fallback if conversion fails\n",
    "                        else:\n",
    "                            print(\"Prediction is None or invalid, skipping trade.\")\n",
    "                            return self.current_price  # Fallback to current price if None\n",
    "                    else:\n",
    "                        print(f\"Failed to fetch prediction: {resp.status}\")\n",
    "                        return self.current_price  # Fallback to current price\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while fetching prediction: {str(e)}\")\n",
    "            return self.current_price\n",
    "\n",
    "\n",
    "    async def market_sentiment(self):\n",
    "        # Fetch the technical indicators and fear/greed index\n",
    "        indicators = await self.fetch_technical_indicators()\n",
    "        fear_greed = self.fetch_fear_greed_index()\n",
    "\n",
    "        # Initialize sentiment\n",
    "        sentiment = 'neutral'\n",
    "        sentiment_score = 0\n",
    "\n",
    "        # Check SMA/EMA crossover signals\n",
    "        if indicators['sma_5'] > indicators['ema_12']:  # Bullish signal\n",
    "            sentiment = 'bullish'\n",
    "            sentiment_score += 1\n",
    "        elif indicators['ema_5'] < indicators['sma_12']:  # Bearish signal\n",
    "            sentiment = 'bearish'\n",
    "            sentiment_score -= 1\n",
    "\n",
    "        #print(fear_greed)\n",
    "        # Adjust sentiment based on Fear and Greed index\n",
    "        if fear_greed:\n",
    "            if fear_greed < 30:  # Extreme Fear\n",
    "                sentiment_score -= 0.5\n",
    "            elif fear_greed > 70:  # Greed\n",
    "                sentiment_score += 0.5\n",
    "\n",
    "        atr = indicators['atr']  # ATR fetched from the technical indicator function\n",
    "\n",
    "        print(\"Market Sentiment & Score:\", sentiment, sentiment_score)\n",
    "        print(\"ATR Value:\", atr)\n",
    "\n",
    "        return sentiment, sentiment_score, atr\n",
    "\n",
    "        # Calculate SMA\n",
    "    def calculate_sma(self, prices, window):\n",
    "        return sum(prices[-window:]) / window\n",
    "\n",
    "    # Calculate EMA\n",
    "    def calculate_ema(self, prices, window):\n",
    "        ema_values = []\n",
    "        multiplier = 2 / (window + 1)\n",
    "        ema_values.append(prices[0])  # Set the first value as the initial EMA\n",
    "        for price in prices[1:]:\n",
    "            ema = (price - ema_values[-1]) * multiplier + ema_values[-1]\n",
    "            ema_values.append(ema)\n",
    "        return ema_values[-1]\n",
    "\n",
    "\n",
    "        # Fetch OHLCV and calculate SMA and EMA\n",
    "    async def fetch_technical_indicators(self):\n",
    "        ohlcv_data = await self.jdk.get_ohlcv(\n",
    "            asset=PerpetualAssetType.ETH,\n",
    "            resolution=Interval.five_minute,\n",
    "            start_days_behind=1 / 24, \n",
    "            end_days_behind=0  # Now\n",
    "        )\n",
    "\n",
    "        ohlcv_data_15m = await self.jdk.get_ohlcv(\n",
    "            asset=PerpetualAssetType.ETH,\n",
    "            resolution=Interval.fifteen_minute,\n",
    "            start_days_behind=1 / 24, \n",
    "            end_days_behind=0  # Now\n",
    "        )\n",
    "\n",
    "        close_prices = ohlcv_data['close'].tolist()\n",
    "        high_prices = ohlcv_data['high'].tolist()\n",
    "        low_prices = ohlcv_data['low'].tolist()\n",
    "\n",
    "        close_prices_15m = ohlcv_data_15m['close'].tolist()\n",
    "\n",
    "        # Calculate SMA and EMA for 10-period and 40-period\n",
    "        sma_5 = self.calculate_sma(close_prices, 4)\n",
    "        ema_5 = self.calculate_ema(close_prices, 4)\n",
    "        sma_12 = self.calculate_sma(close_prices, 10)\n",
    "        ema_12 = self.calculate_ema(close_prices, 10)\n",
    "\n",
    "        # Calculate 15-minute indicators\n",
    "        sma_5_15m = self.calculate_sma(close_prices_15m, 5)\n",
    "        ema_5_15m = self.calculate_ema(close_prices_15m, 5)\n",
    "        sma_12_15m = self.calculate_sma(close_prices_15m, 12)\n",
    "        ema_12_15m = self.calculate_ema(close_prices_15m, 12)\n",
    "\n",
    "        atr_period = 12\n",
    "        atr = self.calculate_atr(high_prices, low_prices, close_prices, atr_period)\n",
    "\n",
    "        return {\n",
    "            \"sma_5\": sma_5,\n",
    "            \"ema_5\": ema_5,\n",
    "            \"sma_12\": sma_12,\n",
    "            \"ema_12\": ema_12,\n",
    "            \"sma_5_15m\": sma_5_15m,\n",
    "            \"ema_5_15m\": ema_5_15m,\n",
    "            \"sma_12_15m\": sma_12_15m,\n",
    "            \"ema_12_15m\": ema_12_15m,\n",
    "            \"current_price\": close_prices[-1],  # Latest price\n",
    "            \"atr\": atr\n",
    "        }\n",
    "\n",
    "    def calculate_atr(self, high_prices, low_prices, close_prices, period):\n",
    "        \"\"\"\n",
    "        Calculate the Average True Range (ATR) over a given period.\n",
    "        \"\"\"\n",
    "        tr_list = []\n",
    "        for i in range(1, len(close_prices)):\n",
    "            high_low = high_prices[i] - low_prices[i]\n",
    "            high_close_prev = abs(high_prices[i] - close_prices[i - 1])\n",
    "            low_close_prev = abs(low_prices[i] - close_prices[i - 1])\n",
    "            true_range = max(high_low, high_close_prev, low_close_prev)\n",
    "            tr_list.append(true_range)\n",
    "    \n",
    "        # Convert to numpy array for easier manipulation\n",
    "        tr_array = np.array(tr_list)\n",
    "        \n",
    "        # Use simple moving average of True Range to calculate ATR\n",
    "        atr = np.mean(tr_array[-period:])\n",
    "        return atr\n",
    "\n",
    "    def fetch_fear_greed_index(self):\n",
    "        response = requests.get(\"https://api.alternative.me/fng/?limit=1\")\n",
    "        if response.status_code == 200:\n",
    "            fear_greed_data = response.json()\n",
    "            return int(fear_greed_data['data'][0]['value'])\n",
    "        return None\n",
    "\n",
    "    def calculate_dynamic_levels(self, sentiment_score, atr, base_stop_loss=0.05, base_take_profit=0.05, atr_threshold_high=7, atr_threshold_low=3):\n",
    "        \"\"\"\n",
    "        Dynamically adjusts stop loss and take profit levels based on sentiment score and ATR.\n",
    "        \"\"\"\n",
    "        stop_loss_multiplier = 1 + abs(sentiment_score)\n",
    "        take_profit_multiplier = 1 + abs(sentiment_score)\n",
    "    \n",
    "        # Adjust SL and TP based on ATR values\n",
    "        if atr > atr_threshold_high:  # High volatility\n",
    "            tp_adjustment_factor = 1.5  # Increase TP and SL range by 50%\n",
    "        elif atr < atr_threshold_low:  # Low volatility\n",
    "            tp_adjustment_factor = 0.75  # Decrease TP and SL by 25%\n",
    "        else:  # Normal volatility\n",
    "            tp_adjustment_factor = 1  # No change\n",
    "    \n",
    "        # Scale stop-loss and take-profit based on sentiment and ATR\n",
    "        stop_loss = base_stop_loss * stop_loss_multiplier * tp_adjustment_factor\n",
    "        take_profit = base_take_profit * take_profit_multiplier * tp_adjustment_factor\n",
    "        \n",
    "        return stop_loss, take_profit\n",
    "\n",
    "        \n",
    "\n",
    "    async def handle_buy_trade(self, sentiment_score, stop_loss, take_profit, position_size):\n",
    "        try:\n",
    "\n",
    "            # Monitor existing trades before executing the sell\n",
    "            can_trade = await self.monitor_open_trades()\n",
    "            \n",
    "            if not can_trade:\n",
    "                print(\"Active position detected. Skipping buy trade execution.\")\n",
    "                return\n",
    "                \n",
    "            current_price_decimal = Decimal(str(self.current_price))\n",
    "            take_profit_decimal = Decimal(str(take_profit))\n",
    "            stop_loss_decimal = Decimal(str(stop_loss))\n",
    "    \n",
    "            # Calculate the take-profit price (where you want to sell to take profit)\n",
    "            take_profit_price = current_price_decimal * (Decimal('1') + take_profit_decimal / Decimal('100'))\n",
    "            take_profit_price = take_profit_price.quantize(self.quote_tick)  # Round to tick size\n",
    "            \n",
    "            # Calculate the stop-loss price (where you want to sell if the market goes against you)\n",
    "            stop_loss_price = current_price_decimal * (Decimal('1') - stop_loss_decimal / Decimal('100'))\n",
    "            stop_loss_price = stop_loss_price.quantize(self.quote_tick)  # Round to tick size\n",
    "    \n",
    "            if position_size <= Decimal('0.00'):\n",
    "                print(\"Position size is zero or invalid, cannot place the order.\")\n",
    "                return\n",
    "                \n",
    "            # Step 1: Place a market buy order to open a position\n",
    "            await jdk.make_order(\n",
    "                amount=position_size,\n",
    "                asset=PerpetualAssetType.ETH,\n",
    "                is_buy=True  # True indicates a buy order\n",
    "            )\n",
    "            print(\"Market BUY Order placed...\")\n",
    "    \n",
    "            # Step 2: Place a limit sell order to take profit at the target price\n",
    "            await jdk.make_limit_order(\n",
    "                amount=position_size,\n",
    "                price=take_profit_price,\n",
    "                asset=PerpetualAssetType.ETH,\n",
    "                is_buy=False  # False indicates a sell order to close the position\n",
    "            )\n",
    "            print(f\"Take Profit Limit SELL Order placed at {take_profit_price}...\")\n",
    "    \n",
    "            # Step 3: Place a stop-loss order to sell if the price drops to the stop-loss level\n",
    "            # await jdk.make_limit_order(\n",
    "            #     amount=position_size,\n",
    "            #     price=stop_loss_price,\n",
    "            #     asset=PerpetualAssetType.ETH,\n",
    "            #     is_buy=False  # False indicates a sell order to close the position\n",
    "            # )\n",
    "            # print(f\"Stop Loss Order placed at {stop_loss_price}.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in handle_buy_trade: {e}\")\n",
    "\n",
    "\n",
    "    async def handle_sell_trade(self, sentiment_score, stop_loss, take_profit, position_size):\n",
    "        \"\"\"\n",
    "        Handle the logic for executing a sell trade (short sell) and then buying back at a lower price.\n",
    "        Includes error handling for the trading orders.\n",
    "        \"\"\"  \n",
    "        # Monitor existing trades before executing the sell\n",
    "        can_trade = await self.monitor_open_trades()\n",
    "        \n",
    "        if not can_trade:\n",
    "            print(\"Active position detected. Skipping sell trade execution.\")\n",
    "            return\n",
    "                   \n",
    "        current_price_decimal = Decimal(str(self.current_price))\n",
    "        take_profit_decimal = Decimal(str(take_profit))\n",
    "        stop_loss_decimal = Decimal(str(stop_loss))\n",
    "    \n",
    "            # Calculate take-profit price for short sell\n",
    "        take_profit_price = current_price_decimal * (Decimal('1') - take_profit_decimal / Decimal('100'))\n",
    "        take_profit_price = take_profit_price.quantize(self.quote_tick)  # Quantize for order book precision\n",
    "\n",
    "        stop_loss_price = current_price_decimal * (Decimal('1') + stop_loss_decimal / Decimal('100'))\n",
    "        stop_loss_price = stop_loss_price.quantize(self.quote_tick)\n",
    "            # 1. Short sell at the current price\n",
    "            # await self.track_metrics(trade_executed=True, position_size=position_size)\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            await jdk.make_order(\n",
    "                amount=position_size,\n",
    "                asset=PerpetualAssetType.ETH,\n",
    "                is_buy=False\n",
    "            )\n",
    "            print(f\"Market SELL Order placed...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error placing short sell order: {e}\")\n",
    "            return\n",
    "    \n",
    "        try:\n",
    "            # 2. Set take-profit order to buy back at a lower price (cover short position)\n",
    "            await jdk.make_limit_order(\n",
    "                amount=position_size,\n",
    "                price=take_profit_price,\n",
    "                asset=PerpetualAssetType.ETH,\n",
    "                is_buy=True\n",
    "            )\n",
    "            print(f\"Take Profit Limit BUY Order placed at {take_profit_price}...\")    \n",
    "        except Exception as e:\n",
    "            print(f\"Error placing take-profit order: {e}\")\n",
    "    \n",
    "        # try:\n",
    "        #     # 3. Set a stop-loss to buy back if the market goes against the short position\n",
    "        #     await jdk.make_limit_order(\n",
    "        #         amount=position_size,\n",
    "        #         price=stop_loss_price,\n",
    "        #         asset=PerpetualAssetType.ETH,\n",
    "        #         is_buy=True                       \n",
    "        #     )\n",
    "        #     print(f\"Stop-loss buy order placed at price: {stop_loss_price}\")   \n",
    "\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error placing stop-loss order: {e}\")\n",
    "        \n",
    "    async def calculate_position_size(self, sentiment_score):\n",
    "        try:\n",
    "            base_position_size = Decimal(self.acct_balance) * (Decimal(self.risk) / Decimal(100))\n",
    "            dynamic_position_size = base_position_size * (Decimal('1') + abs(Decimal(sentiment_score)))\n",
    "            # print(f\"Base Position Size: {base_position_size}\")\n",
    "            # print(f\"Dynamic Position Size: {dynamic_position_size}\")\n",
    "\n",
    "            # print(\"acct balance\", self.acct_balance)\n",
    "            # print(\"risk\", self.risk)\n",
    "            current_price_decimal = Decimal(str(self.current_price))\n",
    "            purchase_amount = (dynamic_position_size / current_price_decimal).quantize(self.quote_tick)\n",
    "            \n",
    "            if purchase_amount < Decimal('0.01'):  # Ensure this is your market's min order size\n",
    "                print(\"Calculated purchase amount is below the minimum order size. Increase your risk Level .... Defaulting\")\n",
    "                purchase_amount = Decimal('0.01')\n",
    "            \n",
    "            print(f\"Purchase Amt (ETH): {purchase_amount}\")\n",
    "            return purchase_amount\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in calculate_position_size: {e}\")\n",
    "            return None  # Return None in case of an error\n",
    "            \n",
    "    async def fetch_current_price(self):\n",
    "        \"\"\"\n",
    "        Fetch the current price of the asset from the market.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Request OHLCV data for the asset from the last minute\n",
    "            ohlcv_data = await jdk.get_ohlcv(\n",
    "                asset=PerpetualAssetType.ETH,\n",
    "                resolution=Interval.five_minute,\n",
    "                start_days_behind=2.5 / 24,  # 2.5 hours ago\n",
    "                end_days_behind=0  # Now\n",
    "            )\n",
    "            \n",
    "            self.current_price = ohlcv_data['close'].iloc[-1]\n",
    "            return self.current_price\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching current price: {e}\")\n",
    "            return None  # Return None in case of an error\n",
    "\n",
    "    async def monitor_open_trades(self):\n",
    "        \"\"\"\n",
    "        Monitor open trades and manage positions and incomplete orders.\n",
    "        \"\"\"\n",
    "        asset = PerpetualAssetType.ETH\n",
    "        profit_threshold = Decimal(\"3\")\n",
    "        try:\n",
    "            # Fetch all positions\n",
    "            positions = await jdk.positions()\n",
    "            position_rows = positions.rows\n",
    "    \n",
    "            # Filter positions for ETH perpetual symbol\n",
    "            eth_perp_positions = [\n",
    "                pos for pos in position_rows if pos.symbol == asset\n",
    "            ]\n",
    "    \n",
    "            # Check if any position is exactly zero, otherwise consider it as active\n",
    "            position_qty = sum(pos.position_qty for pos in eth_perp_positions)\n",
    "            active_position = position_qty != 0\n",
    "    \n",
    "            # Fetch incomplete orders\n",
    "            orders: list[Order] = await jdk.orders(status=\"INCOMPLETE\")\n",
    "            print(f\"Found {len(orders)} incomplete orders.\")\n",
    "    \n",
    "            # Track if a position has been closed\n",
    "            position_closed = False\n",
    "    \n",
    "            # If there are no positions at all, we consider trading safe to resume\n",
    "            if position_qty == 0:\n",
    "                print(\"No positions open. Safe to resume trading.\")\n",
    "                position_closed = True\n",
    "    \n",
    "            if active_position and abs(position_qty) > Decimal(\"0.01\"):\n",
    "                # Fetch the average open price and mark price for the position\n",
    "                for eth_position in eth_perp_positions:\n",
    "                    avg_open_price = eth_position.average_open_price\n",
    "                    mark_price = eth_position.mark_price\n",
    "                    unrealized_pnl = mark_price - avg_open_price\n",
    "                    print(f\"Unrealized PnL: {unrealized_pnl}\")\n",
    "    \n",
    "                    # Check if the position is losing (negative PnL) and close TP and position\n",
    "                    if unrealized_pnl < Decimal(\"0\") or unrealized_pnl >= profit_threshold:  # or a custom negative threshold\n",
    "                        # Close take-profit and position\n",
    "                        for order in orders:\n",
    "                            await self.cancel_order(order.order_id)\n",
    "                            print(f\"Cancelled TP order ID {order.order_id} as the position is losing.\")\n",
    "                        # Add logic to close the open position (market close)\n",
    "                        await jdk.close_position(asset)\n",
    "                        print(f\"Closed losing position for {asset}.\")\n",
    "                        position_closed = True\n",
    "    \n",
    "            else:\n",
    "                # If no active positions, close any incomplete orders\n",
    "                for order in orders:\n",
    "                    await self.cancel_order(order.order_id)\n",
    "                    print(f\"Cancelled incomplete order ID {order.order_id} as there are no active positions.\")\n",
    "                    position_closed = True  # Consider this as closing open activities\n",
    "    \n",
    "            # After checking the open trades, decide if you can resume normal trading\n",
    "            if position_closed:\n",
    "                print(\"Position is closed or none exist.\")\n",
    "                return True  # Resume normal trading\n",
    "            else:\n",
    "                print(\"Active position found. Skipping new trades.\")\n",
    "                return False  # Do not resume trading\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving open orders or positions: {e}\")\n",
    "            return False  # In case of error, avoid placing new trades\n",
    "\n",
    "    async def cancel_order(self, order_id: str):\n",
    "        \"\"\"\n",
    "        Cancels an order by its ID and symbol.\n",
    "        \"\"\"\n",
    "        path = f\"v1/order\"\n",
    "        params = {\n",
    "            \"order_id\": order_id,\n",
    "            \"symbol\": 'PERP_ETH_USDC'\n",
    "        }\n",
    "        \n",
    "        # Send the DELETE request using the SDK's signing mechanism\n",
    "        response_json = await jdk._send_request_async(path, params=params, method=\"DELETE\")\n",
    "        print(response_json)\n",
    "        \n",
    "        if response_json[\"success\"]:\n",
    "            return response_json\n",
    "        else:\n",
    "            raise ValueError(response_json)\n",
    "            \n",
    "    async def track_metrics(self, trade_executed: bool, position_size):\n",
    "        \"\"\"\n",
    "        After every 10 trades, calculate the Sharpe Ratio and plot PnL graph.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Only increment trade_count if a trade was executed\n",
    "            if trade_executed:\n",
    "                self.trade_count += 1\n",
    "    \n",
    "                # Fetch position data\n",
    "                positions = await jdk.positions()  # Fetch positions from your platform\n",
    "    \n",
    "                # Calculate returns only if a trade was executed (ignores hold periods)\n",
    "                position_data = [pos for pos in positions.rows if pos.symbol == PerpetualAssetType.ETH]\n",
    "\n",
    "                current_price_decimal = Decimal(str(self.current_price))\n",
    "                investment = current_price_decimal * position_size\n",
    "                trade_returns = await self.calculate_returns(position_data, investment)\n",
    "                self.returns.extend(trade_returns)\n",
    "                self.cumulative_loss += await self.calculate_cumulative_loss(position_data)\n",
    "\n",
    "                # Extract PnL for plotting and extend history\n",
    "                pnl_values = [float(pos.pnl_24_h) for pos in position_data]\n",
    "                self.pnl_history.extend(pnl_values)  # Accumulate across trades\n",
    "    \n",
    "                print(\"Cumulative Loss:\", self.cumulative_loss)\n",
    "                print(\"Trade Returns:\", trade_returns)\n",
    "                print(\"Trade Count:\", self.trade_count)\n",
    "    \n",
    "            else:\n",
    "                print(\"No trades executed. Skipping return calculation...\")\n",
    "    \n",
    "            # Every 10 trades, calculate metrics and adjust risk\n",
    "            if self.trade_count % 3 == 0 and trade_executed:\n",
    "                if self.cumulative_loss > self.max_drawdown:\n",
    "                    print(\"Max drawdown limit reached, reducing risk.\")\n",
    "                    self.risk -= float(Decimal('0.02'))  # Convert Decimal to float before dividing\n",
    "                    print(f\"Max drawdown limit reached, reducing risk. New Risk: {self.risk}\")\n",
    "                    self.cumulative_loss = Decimal('0')  # Reset after adjusting\n",
    "                    \n",
    "                elif self.cumulative_loss < self.min_cumulative_loss_threshold or self.risk < 0.3:\n",
    "                    print(\"Not enough risk taken, increasing risk.\")\n",
    "                    self.risk += float(Decimal('0.02'))  # Increase risk by 50%\n",
    "                    self.cumulative_loss = Decimal('0')  # Reset after adjusting\n",
    "    \n",
    "                sharpe_ratio = await self.calculate_sharpe_ratio(self.returns)\n",
    "                print(f\"Sharpe Ratio: {sharpe_ratio}\")\n",
    "    \n",
    "                # Plot the PnL graph\n",
    "                self.plot_pnl(self.pnl_history)\n",
    "    \n",
    "                # Reset trade count after processing\n",
    "                self.trade_count = 0\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in track_metrics: {e}\")\n",
    "\n",
    "    \n",
    "    async def calculate_returns(self, position_data, investment):\n",
    "        \"\"\"\n",
    "        Calculate returns based on pnl data from position.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            returns = []\n",
    "            investment_float = float(investment)\n",
    "            for pos in position_data:\n",
    "                pnl = float(pos.pnl_24_h)  # Convert Decimal to float for easier calculations\n",
    "                initial_investment = investment_float\n",
    "                if initial_investment != 0:\n",
    "                    # Calculate return as PnL / initial cost\n",
    "                    returns.append(pnl / initial_investment)\n",
    "                else:\n",
    "                    print(\"No initial investment, skipping return calculation.\")\n",
    "            return returns\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in calculate_returns: {e}\")\n",
    "            return []\n",
    "\n",
    "    \n",
    "    async def calculate_cumulative_loss(self, position_data):\n",
    "        \"\"\"\n",
    "        Calculate cumulative loss from the positions.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            cumulative_loss = Decimal('0')\n",
    "            for pos in position_data:\n",
    "                pnl = pos.unsettled_pnl\n",
    "                if pnl < 0:\n",
    "                    cumulative_loss += abs(pnl)\n",
    "            return cumulative_loss\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in calculate_cumulative_loss: {e}\")\n",
    "            return Decimal('0')\n",
    "    \n",
    "    async def calculate_sharpe_ratio(self, returns, risk_free_rate=0.01):\n",
    "        \"\"\"\n",
    "        Calculate the Sharpe Ratio for a given set of returns.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            avg_return = np.mean(returns)\n",
    "            std_return = np.std(returns)\n",
    "            sharpe_ratio = (avg_return - risk_free_rate) / std_return if std_return != 0 else 0\n",
    "            return sharpe_ratio\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in calculate_sharpe_ratio: {e}\")\n",
    "            return 0\n",
    "    \n",
    "    def plot_pnl(self, pnl_history):\n",
    "        \"\"\"\n",
    "        Plot the Profit and Loss (PnL) graph using the accumulated PnL history.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            trades = range(1, len(pnl_history) + 1)  # X-axis as trade numbers\n",
    "    \n",
    "            plt.figure(figsize=(5, 3))\n",
    "            plt.plot(trades, pnl_history, marker='o', linestyle='-', color='b')\n",
    "            plt.title(\"PnL over Trades\")\n",
    "            plt.xlabel(\"Trade Number\")\n",
    "            plt.ylabel(\"PnL (Unsettled)\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in plot_pnl: {e}\")\n",
    "\n",
    "    async def check_account_status(self, sentiment):\n",
    "        try:\n",
    "            # Check if the account is registered with the broker\n",
    "            account_info = await jdk.get_account(address=jdk._wallet.address, broker_id=\"empyreal\")\n",
    "            if not account_info:\n",
    "                raise ValueError(\"Account is not registered or cannot be found.\")\n",
    "\n",
    "            # Retrieve open positions\n",
    "            positions = await jdk.positions()\n",
    "\n",
    "            # print(positions)\n",
    "\n",
    "            positionone = await jdk.position(PerpetualAssetType.ETH)\n",
    "\n",
    "            #print(positionone)\n",
    "\n",
    "            dummypnl = await jdk.get_market_info(PerpetualAssetType.ETH)\n",
    "\n",
    "            #print(dummypnl)\n",
    "\n",
    "        \n",
    "            # await self.manage_positions(sentiment)\n",
    "            \n",
    "            orders: list[Order] = await jdk.orders(status=\"INCOMPLETE\")\n",
    "            \n",
    "            position_rows = positions.rows\n",
    "            # Filter positions for ETH perpetual symbol\n",
    "            eth_perp_positions = [\n",
    "                pos for pos in position_rows if pos.symbol == PerpetualAssetType.ETH\n",
    "            ]\n",
    "            \n",
    "            free_collateral = positions.free_collateral\n",
    "    \n",
    "            # If any ETH positions are found, print relevant details\n",
    "            for eth_position in eth_perp_positions:\n",
    "                print(f\"All Pos Qty: {eth_position.position_qty}\")\n",
    "                print(f\"Long Pos Qty: {eth_position.pending_long_qty}\")\n",
    "                print(f\"Short Pos Qty: {eth_position.pending_short_qty}\")\n",
    "                print(f\"PnL (24h): {eth_position.pnl_24_h}\")\n",
    "                print(f\" Fees (2h): {eth_position.fee_24_h}\")\n",
    "    \n",
    "            return {\n",
    "                \"positions\": eth_perp_positions,\n",
    "                \"position_qty\": eth_position.position_qty,\n",
    "                \"free_collateral\": free_collateral,\n",
    "                \"incomplete_orders\": len(orders),\n",
    "            }\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error in checking account status: {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab05bf14-4f2a-4772-8a9b-033161df20cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trade logic...\n",
      "[2381.67, 2383.08, 2383.98] ['up', 'up']\n",
      "Current price (ETH): 2383.98\n",
      "Data successfully sent to cloud function.\n",
      "Predicted Price: 2383.6333459615\n",
      "Market Sentiment & Score: bullish 1\n",
      "ATR Value: 2.579090909090858\n",
      "All Pos Qty: 0.04\n",
      "Long Pos Qty: 0.0\n",
      "Short Pos Qty: -0.04\n",
      "PnL (24h): -2.4874\n",
      " Fees (2h): 6.255226\n",
      "Free Collateral: 956.535093\n",
      "incomplete order 1\n",
      "Price Diff [Prediction & Current]: -0.34665403850021903\n",
      "Found 1 incomplete orders.\n",
      "Unrealized PnL: 0.51\n",
      "Active position found. Skipping new trades.\n",
      "Purchase Amt (ETH): 0.04\n",
      "Found 1 incomplete orders.\n",
      "Unrealized PnL: 0.49\n",
      "Active position found. Skipping new trades.\n",
      "Active position detected. Skipping buy trade execution.\n",
      "Cumulative Loss: 67.899894\n",
      "Trade Returns: [-0.026084530910494216]\n",
      "Trade Count: 2\n",
      "Waiting for next iteration in 5 minutes...\n"
     ]
    }
   ],
   "source": [
    "# Check if another user is currently running the trading strategy\n",
    "# if check_lock():\n",
    "#     print(\"Another user is currently running the trading strategy. Please wait.\")\n",
    "# else:\n",
    "#     # Create a lock file to prevent others from running the strategy\n",
    "#     create_lock()\n",
    "    \n",
    "    # Stop and delete existing strategy instance if running\n",
    "if 'strategy' in globals():\n",
    "    strategy.stop()  # Release lock when the strategy is stopped\n",
    "    del strategy\n",
    "\n",
    "# Initialize EmpOrderly SDK with initial capital and parameters\n",
    "sdk = EmpOrderly(\n",
    "    cash=10000,\n",
    "    commission=0.0000001,\n",
    "    exclusive_orders=True\n",
    ")\n",
    "\n",
    "# Initialize EmpyrealOrderlySDK with wallet details and testnet config\n",
    "jdk = EmpyrealOrderlySDK(pvt_hex=wallet['private_key'], account_id=account_id, is_testnet=True)\n",
    "\n",
    "# Define strategy parameters including risk, account balance, max drawdown, and SDK instance\n",
    "params = {\"risk\": 0.6, \"acct_balance\": sdk.cash, \"max_drawdown\": 50, \"jdk\": jdk}\n",
    "\n",
    "# Load historical data for analysis, using a lookback window and asset type\n",
    "data = await sdk.load_data(\n",
    "    lookback=5,\n",
    "    interval=Interval.five_minute,\n",
    "    asset=PerpetualAssetType.ETH,\n",
    ")\n",
    "\n",
    "# Set broker for the strategy\n",
    "broker = 'orderly'\n",
    "\n",
    "# Initialize and set the strategy with broker, data, and params\n",
    "sdk.set_strategy(AIEventDrivenStrategy)\n",
    "\n",
    "# Start the trading strategy\n",
    "strategy = AIEventDrivenStrategy(broker=broker, data=data, params=params)\n",
    "\n",
    "# Execute the next step in the strategy\n",
    "strategy.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4651e355-055a-4b64-9d34-898ddcad29c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading will stop immediately.\n",
      "Trading loop was cancelled.\n"
     ]
    }
   ],
   "source": [
    "strategy.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe2d832-bd01-4804-9dc7-a1cc6a06d482",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "release_lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7eb52bd-401f-4b22-8c2e-791c5c01cf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asset=None cash=10000.0 commission=1e-07 margin=1.0 sdk=EmpyrealOrderlySDK(account_id='0xeffefc0efde28f5230a962c97a9e6badbae46c407c75aa4749063c5bebbe909b', pvt_hex='30e6cd50e6f7110d63e1fd83a68d0a46a8d11932635fae36642a0c68ef72fe28', is_testnet=True) trade_on_close=False hedging=False exclusive_orders=True\n"
     ]
    }
   ],
   "source": [
    "print(sdk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a49db-9f3b-46f0-8fb4-f63a6c8dc4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
